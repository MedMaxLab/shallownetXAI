{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad69f38-cf63-4652-b9e1-a502e079a38d",
   "metadata": {},
   "source": [
    "# Analytical Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac6c09-2510-46e5-89a6-69dc283ffc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import importlib\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.stats import multitest\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "from collections import defaultdict\n",
    "from scipy.stats import linregress\n",
    "import torch\n",
    "from AllFnc import eegvislib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = RuntimeWarning)\n",
    "\n",
    "# SET PATH\n",
    "sep         = os.path.sep\n",
    "dataPath    = '/data/delpup/datasets/eegpickle/'\n",
    "osPath      = os.path.abspath(os.getcwd())\n",
    "imgPath     = osPath + sep + 'imgs' + sep\n",
    "modelsPath  = osPath + sep + 'AlzClassification' + sep + 'Models' + sep\n",
    "resultsPath = osPath + sep + 'AlzClassification' + sep + 'Results' + sep\n",
    "numericPath = osPath + sep + 'AnalyticalCalculation' + sep\n",
    "\n",
    "# IMGS OPTIONS\n",
    "imgs_format = '.pdf'\n",
    "save_img    = True\n",
    "\n",
    "outerFolds  = 10\n",
    "innerFolds  = 5\n",
    "classlabels = ['CTL', 'FTD', 'AD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba04fe8-43e9-4c1e-84d6-5603c49e6ca9",
   "metadata": {},
   "source": [
    "## Analysis First Layer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a27a31-3e3f-4943-9476-ce807573594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change_load(path, split, mod, model, metric):\n",
    "    \"\"\"\n",
    "    Load weight change data and a specific performance metric from pickle files.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path (str): Directory path for the model files.\n",
    "    - split (tuple): Tuple specifying outer and inner folds as (outerFold, innerFold).\n",
    "    - mod (str): Modifier string to identify the file.\n",
    "    - model (str): Model identifier.\n",
    "    - metric (str): Performance metric to load.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    - dw (numpy.ndarray): Flattened weight change array scaled by 100.\n",
    "    - bacc (float): Performance metric value scaled by 100.\n",
    "    \"\"\"\n",
    "    outerFold, innerFold = split\n",
    "\n",
    "    # Load and process weight change data\n",
    "    with open(f'{path}{model}_dw_{outerFold}_{innerFold}_{mod}.pkl', 'rb') as file:\n",
    "        dw_preinit = pickle.load(file)\n",
    "    dw = np.ravel(dw_preinit.numpy()) * 100  # Flatten and scale\n",
    "\n",
    "    # Load and process performance metric data\n",
    "    with open(f'{path}{model}_scores_{outerFold}_{innerFold}_{mod}.pkl', 'rb') as file:\n",
    "        bacc = pickle.load(file)[metric]\n",
    "    bacc *= 100  # Scale the performance metric\n",
    "\n",
    "    return dw, bacc\n",
    "\n",
    "def weight_change_plot(path, mod, model, splits, spec_dict):\n",
    "    \"\"\"\n",
    "    Plot the histogram of weight changes across specified splits.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path (str): Folder to path used by the function weight_change_load.\n",
    "    - mod (str): Modifier string to identify the file.\n",
    "    - model (str): Model identifier.\n",
    "    - splits (list): List of split tuples [(outerFold1, innerFold1), (outerFold2, innerFold2), ...].\n",
    "    - spec_dict (dict): A dictionary containing various specification parameters \n",
    "    and other plotting configurations.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    - fig (matplotlib.figure.Figure): The generated plot figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "    ax.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "\n",
    "    for split in splits:\n",
    "        # Load metrics for each split\n",
    "        dw_random, bacc_random = weight_change_load(path, split, mod, model, spec_dict['metric'])\n",
    "        \n",
    "        # Clip weight change values to specified limits\n",
    "        dw_random = np.clip(dw_random, -spec_dict['clip'], spec_dict['clip'])\n",
    "\n",
    "        # Compute histogram counts and relative frequencies\n",
    "        counts, bin_edges = np.histogram(dw_random, bins=spec_dict['bins'])\n",
    "        relative_counts = counts * 100 / len(dw_random)  # Convert to percentage\n",
    "\n",
    "        # Plot histogram as a bar chart with relative counts\n",
    "        ax.bar(bin_edges[:-1], relative_counts, width=np.diff(bin_edges), alpha=spec_dict['alpha'],\n",
    "               label=f'Split {split[0]}-{split[1]}', align='edge')\n",
    "\n",
    "    # Set axis labels and customize ticks\n",
    "    ax.set_ylabel('Relative Count %', fontsize=spec_dict['font'] - 2)\n",
    "    ax.set_xlabel(r'$\\Delta_{w\\%} = (w - w_{init})/|w|$', fontsize=spec_dict['font'] - 2)\n",
    "    ax.set_xlim(-spec_dict['clip'], spec_dict['clip'])\n",
    "    ax.set_xticks(np.arange(-spec_dict['clip'], spec_dict['clip'] + spec_dict['ticks'][0], spec_dict['ticks'][0]))\n",
    "    ax.set_yticks(np.arange(0, np.max(relative_counts) + spec_dict['ticks'][1], spec_dict['ticks'][1]))\n",
    "    ax.tick_params(axis='both', labelsize=spec_dict['font'] - 4)\n",
    "    ax.legend(loc=spec_dict['loc'], fontsize=spec_dict['font'] - 6)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1060e-3ddf-4067-8ba2-126040c515ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters\n",
    "mod = 'random'\n",
    "model = 'shn0'\n",
    "splits = [[9, 2], [6, 5]]\n",
    "spec_dict = {\n",
    "    'font': 16,\n",
    "    'clip': 50,\n",
    "    'bins': 40,\n",
    "    'alpha': 0.5,\n",
    "    'ticks': [10, 2],\n",
    "    'title': 'Weights Change in the First Layer ShallowNet',\n",
    "    'figdim': [7, 5],\n",
    "    'loc': 'upper right',\n",
    "    'metric': 'accuracy_weighted',\n",
    "    'filename': 'weightChangeFirstLayer'\n",
    "}\n",
    "\n",
    "# Generate and optionally save the plot\n",
    "fig = weight_change_plot(numericPath + 'Initialization' + sep, mod, model, splits, spec_dict)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['filename'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad008d-5684-4237-9319-7e010535bf9d",
   "metadata": {},
   "source": [
    "## Analysis Topographies Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7773a64-ba79-4a2b-bc87-804a6fb0011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvals_calculation(scalps, indexs, spec_dict):\n",
    "    \"\"\"\n",
    "    Calculate the pairwise p-values and correlation statistics between filter activations across specified scalp maps.\n",
    "    Adjusts p-values for multiple comparisons and returns the corrected p-value matrix and a significance matrix.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - scalps (list of np.ndarray): List of 4D arrays representing the scalp maps. \n",
    "    Each array should have a shape (filters, kernels=1, hight=channels, width=1)    \n",
    "    - indexs (list of int): Indices for two specific scalp maps in `scalps` to compare.\n",
    "    - spec_dict (dict): A dictionary containing various specification parameters \n",
    "    and other plotting configurations.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    - corrected_pvals (np.ndarray): Symmetric matrix of corrected p-values for the pairwise filter comparisons.\n",
    "    - significance_matrix (np.ndarray): Boolean matrix indicating where p-values are significant after correction.\n",
    "    - stats (np.ndarray): Symmetric matrix of pearson coefficients for the pairwise filter comparisons.\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = scalps[0].shape[0]  # Number of filters in each scalp map\n",
    "    pvals = np.zeros((filters, filters))  # Matrix to store p-values\n",
    "    stats = np.zeros((filters, filters))  # Matrix to store correlation statistics\n",
    "\n",
    "    # Calculate pairwise Pearson correlations between filters in specified scalp maps\n",
    "    for i in range(filters):\n",
    "        for j in range(filters):\n",
    "            res = pearsonr(scalps[indexs[0]][i, 0, :, 0], scalps[indexs[1]][j, 0, :, 0])\n",
    "            pvals[i, j] = res.pvalue\n",
    "            stats[i, j] = res.statistic\n",
    "\n",
    "    # Extract the upper triangle of p-values for multiple testing correction\n",
    "    upper_tri_indices = np.triu_indices(filters)\n",
    "    flattened_pvals = pvals[upper_tri_indices].flatten()\n",
    "\n",
    "    # Apply multiple testing correction (e.g., Bonferroni, FDR)\n",
    "    corrected_res = multitest.multipletests(flattened_pvals, alpha=spec_dict['pval'], method=spec_dict['method'])\n",
    "    corrected_pvals_flat = corrected_res[1]  # Corrected p-values\n",
    "    significance_matrix_flat = corrected_res[0]  # Boolean array for significance\n",
    "\n",
    "    # Reconstruct matrices with corrected p-values and significance flags in original dimensions\n",
    "    corrected_pvals = np.zeros((filters, filters))\n",
    "    significance_matrix = np.zeros((filters, filters), dtype=bool)\n",
    "\n",
    "    # Map corrected values to the upper triangle\n",
    "    corrected_pvals[upper_tri_indices] = corrected_pvals_flat\n",
    "    significance_matrix[upper_tri_indices] = significance_matrix_flat\n",
    "\n",
    "    # Reflect upper triangle to lower triangle for symmetry\n",
    "    corrected_pvals = corrected_pvals + corrected_pvals.T - np.diag(np.diag(corrected_pvals))\n",
    "    significance_matrix = significance_matrix | significance_matrix.T\n",
    "\n",
    "    return corrected_pvals, significance_matrix, stats\n",
    "\n",
    "\n",
    "def pvals_plot(corrected_pvals, significance_matrix, stats, splits, indexs, spec_dict):\n",
    "    \"\"\"\n",
    "    Plot the significance matrix with annotated corrected p-values for significant comparisons.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - corrected_pvals (np.ndarray): Symmetric matrix of corrected p-values for filter comparisons.\n",
    "    - significance_matrix (np.ndarray): Boolean matrix indicating where p-values are significant.\n",
    "    - stats (np.ndarray): Symmetric matrix of pearson coefficients for the pairwise filter comparisons.\n",
    "    - splits (list of lists): List of split identifiers. \n",
    "    Each identifier is a list of integers representing the split structure.\n",
    "    - indexs (list of int): Indices for two specific scalp maps from `splits` to label in the plot.\n",
    "    - spec_dict (dict): A dictionary containing various specification parameters \n",
    "    and other plotting configurations.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    fig (matplotlib.figure.Figure): The resulting figure with the significance matrix plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = np.shape(corrected_pvals)[0]  # Number of filters\n",
    "\n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "    ax.imshow(significance_matrix, cmap='Greys')  # Display significance matrix\n",
    "    ax.set_ylabel(f'Split {splits[indexs[0]][0]}-{splits[indexs[0]][1]}', fontsize=spec_dict['font']-2)\n",
    "    ax.set_xlabel(f'Split {splits[indexs[1]][0]}-{splits[indexs[1]][1]}', fontsize=spec_dict['font']-2)\n",
    "    ax.set_xticks(np.arange(0, filters, 1))\n",
    "    ax.set_xticklabels(spec_dict['xticks'], fontsize=spec_dict['font']-4)\n",
    "    ax.set_yticks(np.arange(0, filters, 1))\n",
    "    ax.set_yticklabels(spec_dict['xticks'], fontsize=spec_dict['font']-4)\n",
    "    ax.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "\n",
    "    # Annotate significant p-values on the plot\n",
    "    for i in range(filters):\n",
    "        for j in range(filters):\n",
    "            if significance_matrix[i, j]:  # Only annotate cells with significant p-values\n",
    "                adj_R2 = eegvislib.adjusted_R2(stats[i,j], spec_dict['C'], 1)\n",
    "                ax.text(j, i, f'p$={corrected_pvals[i, j]:.1e}$ \\n $\\\\rho({spec_dict['C']})={stats[i,j]:.2f}$ \\n adj.$R^2={adj_R2:.2f}$', \n",
    "                        ha='center', va='center', color='white', fontsize=spec_dict['font']-8)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a17b5a-b8eb-46ac-8399-7aa5448076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [[9, 2], [6, 5]]\n",
    "modelsToimport = ['alz_flt_125_shn7db_009_002_000050_019_004','alz_flt_125_shn7db_006_005_000050_019_004']\n",
    "\n",
    "spec_dict = {'pval': 0.05,\n",
    "             'method': 'holm',\n",
    "             'xticks': ['$\\\\delta$', '$\\\\theta$', '$\\\\alpha$', '$\\\\beta_1$',\n",
    "                       '$\\\\beta_2$', '$\\\\beta_3$', '$\\\\gamma$'],\n",
    "             'C': 19,\n",
    "             'title': f'Significance Correlation (Holm corrected)',\n",
    "             'font': 16,\n",
    "             'figdim': [7, 7]}\n",
    "\n",
    "scalps = []\n",
    "for modelToimport in modelsToimport:\n",
    "    shnm = torch.load(modelsPath + modelToimport + '.pt')    \n",
    "    scalps.append(shnm['encoder.conv2.weight'].numpy())\n",
    "\n",
    "corrected_pvals, significance_matrix, stats = pvals_calculation(scalps, [0,1], spec_dict)\n",
    "fig = pvals_plot(corrected_pvals, significance_matrix, stats, splits, [0,1], spec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c47d45-161c-44be-b95e-dfdedde79449",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_pvals, significance_matrix, stats = pvals_calculation(scalps, [0,0], spec_dict)\n",
    "fig = pvals_plot(corrected_pvals, significance_matrix, stats, splits, [0,0], spec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc4e9f-d7af-4c2d-adcd-2e0110c9b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_pvals, significance_matrix, stats = pvals_calculation(scalps, [1,1], spec_dict)\n",
    "fig = pvals_plot(corrected_pvals, significance_matrix, stats, splits, [1,1], spec_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d817bd-ed9c-4fc0-a249-26931dbc6be3",
   "metadata": {},
   "source": [
    "## Analysis Overlap Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdedc3-8845-408a-992b-5f6f2f8b2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'shn7db' #'shn7db'\n",
    "shns = []\n",
    "acc = []\n",
    "for i in range(1,outerFolds+1):\n",
    "    for j in range(1,innerFolds+1):\n",
    "        file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "        filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "        with open(numericPath + 'Overlap' +sep + 'Results' +sep + filename + '.pickle', 'rb') as f:\n",
    "            shn = pickle.load(f)\n",
    "        shns.append(shn)\n",
    "        with open(resultsPath + filename + '.pickle', 'rb') as f:\n",
    "            shnR = pickle.load(f)\n",
    "        acc.append(shnR['accuracy_weighted'])\n",
    "\n",
    "key_list = list(shn.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd664ee-25cd-445f-ade4-47de7fc01872",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_matrix = np.zeros((len(shns),len(key_list)))\n",
    "for j in range(len(key_list)):\n",
    "    for i in range(len(shns)):\n",
    "        overlap_matrix[i,j] = shns[i][key_list[j]]\n",
    "\n",
    "# Add dependent variable safely\n",
    "keys = [f\"{tup[0]}_{tup[1]}\" for tup in key_list]\n",
    "df = pd.DataFrame(overlap_matrix.copy(),columns = keys)\n",
    "df[\"acc\"] = pd.Series(acc, index=df.index)  # Ensures alignment\n",
    "\n",
    "def transform_label(label):\n",
    "    parts = label.split('_')\n",
    "    return f\"Separability: ${parts[0]}_{parts[1]}~-~{parts[2]}_{parts[3]}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16eecd-94e2-44df-a51f-a3d5c6f29456",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['C_t_C_T'].mean(),df['C_t_C_T'].std())\n",
    "print(df['F_t_F_T'].mean(),df['F_t_F_T'].std())\n",
    "print(df['A_t_A_T'].mean(),df['A_t_A_T'].std())\n",
    "\n",
    "print(df['A_t_C_t'].mean(),df['A_t_C_t'].std())\n",
    "print(df['F_t_C_t'].mean(),df['F_t_C_t'].std())\n",
    "print(df['A_t_F_t'].mean(),df['A_t_F_t'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a1a97-c4de-41b5-be39-165ea570a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct formula syntax\n",
    "model = smf.ols(\"acc ~ \" + \" + \".join(keys), data=df)\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\nRegression Results:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Prune based on p-value\n",
    "pruned_features = [feature for feature, p_value in zip(keys, results.pvalues[1:]) if p_value < 0.05]\n",
    "print(f\"Pruned features: {pruned_features}\")\n",
    "\n",
    "dfc = df[keys].copy()\n",
    "# Add constant (intercept) to the data\n",
    "dfc = sm.add_constant(dfc)\n",
    "vif_data = pd.DataFrame()\n",
    "\n",
    "# Calculate VIF for each feature (excluding the constant column)\n",
    "vif_data[\"feature\"] = dfc.columns[1:]  # Excluding the constant column\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(dfc.values, i), 4) for i in range(1, dfc.shape[1])]\n",
    "\n",
    "# Sort VIF values in descending order\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51af0a-bd39-45d0-b8ac-63ffff693abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dependent variable safely\n",
    "keys = [col for col in df.columns[:-1] if 'v' not in col]\n",
    "dfc  = df[keys]\n",
    "\n",
    "# Correct formula syntax\n",
    "model = smf.ols(\"acc ~ \" + \" + \".join(keys), data=dfc)\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\nRegression Results:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Prune based on p-value\n",
    "pruned_features = [feature for feature, p_value in zip(keys, results.pvalues[1:]) if p_value < 0.05]\n",
    "print(f\"Pruned features: {pruned_features}\")\n",
    "\n",
    "# Add constant (intercept) to the data\n",
    "dfc = sm.add_constant(dfc)\n",
    "vif_data = pd.DataFrame()\n",
    "\n",
    "# Calculate VIF for each feature (excluding the constant column)\n",
    "vif_data[\"feature\"] = dfc.columns[1:]  # Excluding the constant column\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(dfc.values, i), 4) for i in range(1, dfc.shape[1])]\n",
    "\n",
    "# Sort VIF values in descending order\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b3751-ca11-488c-aa84-cf0cf53112a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dependent variable safely\n",
    "keys = [col for col in df.columns[:-1] if 'T' not in col]\n",
    "\n",
    "dfc = df[keys]\n",
    "\n",
    "# Correct formula syntax\n",
    "model = smf.ols(\"acc ~ \" + \" + \".join(keys), data=dfc)\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\nRegression Results:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Prune based on p-value\n",
    "pruned_features = [feature for feature, p_value in zip(keys, results.pvalues[1:]) if p_value < 0.05]\n",
    "print(f\"Pruned features: {pruned_features}\")\n",
    "\n",
    "# Add constant (intercept) to the data\n",
    "dfc = sm.add_constant(dfc)\n",
    "vif_data = pd.DataFrame()\n",
    "\n",
    "# Calculate VIF for each feature (excluding the constant column)\n",
    "vif_data[\"feature\"] = dfc.columns[1:]  # Excluding the constant column\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(dfc.values, i), 4) for i in range(1, dfc.shape[1])]\n",
    "\n",
    "# Sort VIF values in descending order\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a10bec-3bb6-492f-bc4f-1d4e937d1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dependent variable safely\n",
    "keys = [col for col in df.columns[:-1] if 't' not in col]\n",
    "\n",
    "dfc = df[keys]\n",
    "\n",
    "# Correct formula syntax\n",
    "model = smf.ols(\"acc ~ \" + \" + \".join(keys), data=dfc)\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\nRegression Results:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Prune based on p-value\n",
    "pruned_features = [feature for feature, p_value in zip(keys, results.pvalues[1:]) if p_value < 0.05]\n",
    "print(f\"Pruned features: {pruned_features}\")\n",
    "\n",
    "# Add constant (intercept) to the data\n",
    "dfc = sm.add_constant(dfc)\n",
    "vif_data = pd.DataFrame()\n",
    "\n",
    "# Calculate VIF for each feature (excluding the constant column)\n",
    "vif_data[\"feature\"] = dfc.columns[1:]  # Excluding the constant column\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(dfc.values, i), 4) for i in range(1, dfc.shape[1])]\n",
    "\n",
    "# Sort VIF values in descending order\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10170b6-e413-4bba-bdcd-780baca8f50f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Correlation + Forward-Backward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ee29f-3a11-478c-b0dd-dc84618ca813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out=0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    \n",
    "    while True:\n",
    "        changed = False\n",
    "        # Forward step\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype=float)\n",
    "\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "\n",
    "        if not new_pval.empty:\n",
    "            best_feature = new_pval.idxmin()  # Get column name instead of index\n",
    "            best_pval = new_pval.min()\n",
    "            if best_pval < threshold_in:\n",
    "                included.append(best_feature)\n",
    "                changed = True\n",
    "                if verbose:\n",
    "                    print(f'Add  {best_feature:30} with p-value {best_pval:.6f}')\n",
    "\n",
    "        # Backward step\n",
    "        if included:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "            pvalues = model.pvalues.iloc[1:]  # Exclude intercept\n",
    "            \n",
    "            if not pvalues.empty:\n",
    "                worst_feature = pvalues.idxmax()  # Get column name instead of index\n",
    "                worst_pval = pvalues.max()\n",
    "\n",
    "                if worst_pval > threshold_out:\n",
    "                    included.remove(worst_feature)\n",
    "                    changed = True\n",
    "                    if verbose:\n",
    "                        print(f'Drop {worst_feature:30} with p-value {worst_pval:.6f}')\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "\n",
    "    return included\n",
    "    \n",
    "def correlation_pvalues(df, target_col='acc', method='fdr_bh'):\n",
    "    # Extract all columns and initialize the p-value matrix\n",
    "    cols = df.columns\n",
    "    pval_matrix = pd.DataFrame(index=cols, columns=cols, dtype=float)\n",
    "    pvals = []\n",
    "\n",
    "    # Compute p-values for correlation between 'acc' and all other columns\n",
    "    for col in cols:\n",
    "        if col != target_col:  # Skip the 'acc' column itself\n",
    "            corr, pval = pearsonr(df[col],df[target_col])\n",
    "            pvals.append(pval)\n",
    "            pval_matrix.loc[target_col, col] = pval\n",
    "            pval_matrix.loc[col, target_col] = pval  # Mirror the matrix\n",
    "\n",
    "    # Apply multiple comparison correction to the p-values\n",
    "    adjusted_pvals = multitest.multipletests(pvals, method=method)[1]  # Corrected p-values\n",
    "\n",
    "    # Update the p-value matrix with the adjusted p-values\n",
    "    index = 0\n",
    "    for col in cols:\n",
    "        if col != target_col:  # Skip the 'acc' column itself\n",
    "            pval_matrix.loc[target_col, col] = adjusted_pvals[index]\n",
    "            pval_matrix.loc[col, target_col] = adjusted_pvals[index]\n",
    "            index += 1\n",
    "\n",
    "    return pval_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21e679-e098-43a5-8a70-1aaedb07e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'C_t_C_T'\n",
    "print(pearsonr(df[f], df['acc']))\n",
    "plt.scatter(df['acc'],df[f])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390df44a-3d11-4e97-b79d-c9867a8b01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "p_values_corrected = correlation_pvalues(df,target_col='acc', method='holm')  # 'bonferroni' for stricter correction\n",
    "significant_features = p_values_corrected['acc'][p_values_corrected['acc'] < 0.05].index.tolist()\n",
    "\n",
    "# Example Usage\n",
    "X = df.drop(columns=['acc'])  # Features\n",
    "y = df['acc']                 # Target variable\n",
    "resultF = stepwise_selection(X[significant_features], y, significant_features)\n",
    "print(resultF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1900d5b-3bd1-4a3c-8c92-3065e21626b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr().loc['acc',:].loc[significant_features])\n",
    "print(p_values_corrected['acc'][p_values_corrected['acc'] < 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397f0e6-ebf2-4e1f-816e-0878caa57670",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = resultF\n",
    "dfc = df[keys].copy()\n",
    "\n",
    "# Correct formula syntax\n",
    "model = smf.ols(\"acc ~ \" + \" + \".join(keys), data=dfc)\n",
    "results = model.fit()\n",
    "\n",
    "print(\"\\nRegression Results:\")\n",
    "print(results.summary())\n",
    "\n",
    "# Add constant (intercept) to the data\n",
    "dfc = sm.add_constant(dfc)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "\n",
    "# Calculate VIF for each feature (excluding the constant column)\n",
    "vif_data[\"feature\"] = dfc.columns[1:]  # Excluding the constant column\n",
    "vif_data[\"VIF\"] = [round(variance_inflation_factor(dfc.values, i), 4) for i in range(1, dfc.shape[1])]\n",
    "\n",
    "# Sort VIF values in descending order\n",
    "vif_data = vif_data.sort_values(by=\"VIF\", ascending=False)\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665aa42-da9f-43e9-8ddf-f3636e8906e6",
   "metadata": {},
   "source": [
    "### Variables Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89381979-8078-4679-b63e-8116eb555e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 grid of subplots\n",
    "spec_dict = {'font':12,\n",
    "             'linew':1,\n",
    "             'figdim': [12,10],\n",
    "             'figname': 'shn0_overlap'}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop over pairwise combinations and plot in the subplots\n",
    "index = 0\n",
    "for i in range(len(keys)):\n",
    "    for j in range(i + 1, len(keys)):\n",
    "        # Scatter plot for each pairwise combination\n",
    "        ax = axes[index]\n",
    "        scatter = ax.scatter(df[keys[i]], df[keys[j]], c=[i*100 for i in df['acc']], cmap='jet')\n",
    "        \n",
    "        # Add vertical and horizontal lines at the value 1\n",
    "        ax.axvline(1, linestyle='--', color='k', linewidth=1)\n",
    "        ax.axhline(1, linestyle='--', color='k', linewidth=1)\n",
    "        \n",
    "        # Set labels for the axes\n",
    "        ax.set_xlabel(transform_label(keys[i]),fontsize=spec_dict['font']-2)\n",
    "        ax.set_ylabel(transform_label(keys[j]),fontsize=spec_dict['font']-2)\n",
    "        ax.set_title('ShallowNet',fontsize=spec_dict['font'])\n",
    "        \n",
    "        # Add colorbar to the scatter plot\n",
    "        fig.colorbar(scatter, ax=ax, label='Weighted Accuracy %')\n",
    "\n",
    "        # Increment the index for the next subplot\n",
    "        index += 1\n",
    "\n",
    "# Remove the last empty subplot (since we have 3 plots for 3 variables)\n",
    "for i in range(index,2*2):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0959e0-50b2-4f6a-b59f-7beff676cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = resultF.copy()\n",
    "keys.append('acc')\n",
    "# Create a 2x2 grid of subplots\n",
    "spec_dict = {'font':12,\n",
    "             'linew':1,\n",
    "             'figdim': [12,10],\n",
    "             'figname': 'shn7db_overlap'}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop over pairwise combinations and plot in the subplots\n",
    "index = 0\n",
    "for i in range(len(keys)):\n",
    "    for j in range(i + 1, len(keys)):\n",
    "        # Scatter plot for each pairwise combination\n",
    "        ax = axes[index]\n",
    "        scatter = ax.scatter(df[keys[i]], df[keys[j]], c=[i*100 for i in df['acc']], cmap='jet')\n",
    "        \n",
    "        # Add vertical and horizontal lines at the value 1\n",
    "        ax.axvline(1, linestyle='--', color='k', linewidth=1)\n",
    "        #ax.axhline(1, linestyle='--', color='k', linewidth=1)\n",
    "        \n",
    "        # Set labels for the axes\n",
    "        ax.set_xlabel(transform_label(keys[i]),fontsize=spec_dict['font']-2)\n",
    "        ax.set_ylabel('Weighted Accuracy',fontsize=spec_dict['font']-2)\n",
    "        ax.set_title('xEEGNet',fontsize=spec_dict['font'])\n",
    "        \n",
    "        # Add colorbar to the scatter plot\n",
    "        fig.colorbar(scatter, ax=ax, label='Weighted Accuracy %')\n",
    "\n",
    "        # Increment the index for the next subplot\n",
    "        index += 1\n",
    "\n",
    "# Remove the last empty subplot (since we have 3 plots for 3 variables)\n",
    "for i in range(index,2*2):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055ca09-3e62-4549-abfe-ebce24010012",
   "metadata": {},
   "source": [
    "## Analysis Model Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b434f33-7e61-48f9-8ffe-0d37fb42a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"shn0\", \"shn1\", \"shn2\", \"shn3\", \"shn4\", \"shn5\", \"shn67\",\n",
    "          \"shn628\",\"shn663\",\"shn6119\",\"shn6126\",\"shn6127\",\"shn7\",\"shn7db\"]\n",
    "\n",
    "# Set of models for which a specific condition applies\n",
    "model_set = {'shn0', 'shn1', 'shn2', 'shn3'} #These models has not the first layer frozen\n",
    "\n",
    "spec_dict = {'figname': 'modelVarAccvsWeight',\n",
    "             'font': 18,\n",
    "             'linew': 2,\n",
    "             's':4,\n",
    "             'rotation': 45,\n",
    "             'loc': 'upper center',\n",
    "             'title': 'Architecture Variation - Performance',\n",
    "             'accrandom': 1/len(classlabels),\n",
    "             'linestyle': '--',\n",
    "             'markers': ['X','o'],\n",
    "             'ylima': [20,105],\n",
    "             'ylime': [0,200],\n",
    "             'ylimw': [10**1,10**6],\n",
    "             'jitter': 0.02,\n",
    "             'figdim': [15,5],\n",
    "             'color': ['tab:orange','tab:blue']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236a44d-e8f2-4e75-8afe-a0389fb2bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each model\n",
    "total_weights_v = []\n",
    "for model in models:\n",
    "    filename = f'alz_flt_125_{model}_001_001_000050_019_004'\n",
    "    shn = torch.load(modelsPath + filename + '.pt')\n",
    "\n",
    "    total_weights = 0\n",
    "    # Iterate through the state_dict (model weights)\n",
    "    for key, tensor in shn.items():\n",
    "        # Skip specific keys related to batch normalization\n",
    "        if key in ['encoder.batch1.running_mean', 'encoder.batch1.running_var', 'encoder.batch1.num_batches_tracked']:\n",
    "            continue\n",
    "        \n",
    "        # Add the tensor's total number of elements, applying conditions for specific models\n",
    "        if model in model_set:\n",
    "            total_weights += tensor.numel()\n",
    "        elif key not in ['encoder.conv1.weight', 'encoder.conv1.bias']:\n",
    "            total_weights += tensor.numel()\n",
    "    \n",
    "    total_weights_v.append(total_weights)\n",
    "\n",
    "sorted_pairs = sorted(zip(total_weights_v, models))\n",
    "stored = sorted_pairs[0]\n",
    "sorted_pairs[0] = sorted_pairs[1]\n",
    "sorted_pairs[1] = stored\n",
    "\n",
    "# Unzip the sorted pairs to get sorted vector1\n",
    "models = [v for _, v in sorted_pairs]\n",
    "total_weights_v = [v for v, _ in sorted_pairs]\n",
    "\n",
    "print(total_weights_v)\n",
    "\n",
    "models1 = [sorted_pairs[i][1] for i in range(len(models))]\n",
    "# models1[9] = 'ShallowNet'\n",
    "# models1[0] = 'Med-ShallowNet'\n",
    "\n",
    "models1 = ['xEEGNet',\n",
    " 'shn7',\n",
    " 'shn$6_{7}$',\n",
    " 'shn$6_{28}$',\n",
    " 'shn$6_{63}$',\n",
    " 'shn$6_{119}$',\n",
    " 'shn$6_{126}$',\n",
    " 'shn$6_{127}$',\n",
    " 'shn5',\n",
    " 'ShallowNet',\n",
    " 'shn4',\n",
    " 'shn1',\n",
    " 'shn2',\n",
    " 'shn3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9ae6d-a775-4cfb-b138-aeb380fa6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = defaultdict(list)\n",
    "acc_train = {}\n",
    "acc_val = {}\n",
    "# Precompute accuracy values for each model (only once)\n",
    "for model in models:\n",
    "    acct = []  # Reset accuracy list for each model\n",
    "    accv = []\n",
    "    for i in range(1, outerFolds+1):  # Loop over first parameter\n",
    "        for j in range(1, innerFolds+1):  # Loop over second parameter\n",
    "            file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "            filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "\n",
    "            # Load accuracy data from pickle file (avoid reloading for each iteration)\n",
    "            with open(resultsPath + filename + '.pickle', 'rb') as f:\n",
    "                shn = pickle.load(f)\n",
    "\n",
    "            # Append the accuracy to the list\n",
    "            acc_dict[model].append(shn['accuracy_weighted'] * 100)\n",
    "            acct.append(shn['training_loss_curve'])\n",
    "            accv.append(shn['validation_loss_curve'])\n",
    "\n",
    "    # Append the accuracy to the list\n",
    "    acc_train[model] = acct\n",
    "    acc_val[model] = accv\n",
    "    print(f'{model} QCV: {eegvislib.quartile_coefficient_of_variation(acc_dict[model]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b3cc7-a409-4a80-b8a5-4940d301ed4f",
   "metadata": {},
   "source": [
    "### Model Weights vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da635e1e-6681-4ddd-9287-d42d544e6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, \n",
    "                        figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the weights vs models (on the second y-axis, ax2)\n",
    "ax2.plot(range(1, len(models) + 1), total_weights_v, color=spec_dict['color'][0], \n",
    "         marker=spec_dict['markers'][0], linestyle=spec_dict['linestyle'], \n",
    "         linewidth=spec_dict['linew'], label='Weights')\n",
    "\n",
    "# Plot boxplots for all models (on the first y-axis, ax1)\n",
    "box = ax1.boxplot(list(acc_dict.values()), showfliers=False)\n",
    "\n",
    "# Remove median line from boxplot (using more efficient approach)\n",
    "for median in box['medians']:\n",
    "    median.set_visible(False)\n",
    "\n",
    "# Add scatter points (individual accuracy values) for each model\n",
    "for i, model in enumerate(models):\n",
    "    acc = acc_dict[model]\n",
    "    ax1.scatter(np.ones(len(acc)) * (i + 1) + spec_dict['jitter']*np.random.randn(len(acc)), acc,\n",
    "                color='k', alpha=1, s=spec_dict['s'])\n",
    "\n",
    "# Label the first y-axis (for accuracies)\n",
    "ax1.set_ylabel(\"Median Weighted Accuracy %\", color=spec_dict['color'][1], fontsize=spec_dict['font']-2)\n",
    "ax1.set_ylim(spec_dict['ylima'][0], spec_dict['ylima'][1])\n",
    "ax1.set_xlim(0.5, len(models) + 0.75)\n",
    "\n",
    "# Plot the median value as text on the boxplot for each model\n",
    "median_v = [np.median(acc_dict[model]) for model in models]\n",
    "for i, median in enumerate(median_v):\n",
    "    ax1.text(i + 1, spec_dict['ylima'][0]+2, f'{median:.1f}%', ha='center', va='bottom', \n",
    "             color=spec_dict['color'][1], fontsize=spec_dict['font']-6, fontweight='bold')\n",
    "\n",
    "ax1.plot(np.arange(1, 1 + len(models)), median_v, marker=spec_dict['markers'][1], linestyle=spec_dict['linestyle'],\n",
    "         color=spec_dict['color'][1], linewidth=spec_dict['linew'])\n",
    "\n",
    "# Label the second y-axis (for weights)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel(\"$N^{\\\\circ}$ Trainable Parameters\", color=spec_dict['color'][0], fontsize=spec_dict['font']-2)\n",
    "ax2.set_ylim(spec_dict['ylimw'][0], spec_dict['ylimw'][1])\n",
    "\n",
    "# Add a horizontal line at 33.33 for reference\n",
    "ax1.axhline(spec_dict['accrandom']*100, linestyle=spec_dict['linestyle'], linewidth=spec_dict['linew'], color='red')\n",
    "\n",
    "# Add a title to the plot\n",
    "ax1.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "\n",
    "# Create legend\n",
    "legend_elements = [Line2D([0], [0], marker='.', color='k', label='Single Split', linestyle='None'),\n",
    "                   Line2D([0], [0], label=f'{spec_dict['accrandom']:.0%} Random Guess', \n",
    "                          linestyle=spec_dict['linestyle'], linewidth=spec_dict['linew'], color='red')]\n",
    "ax1.legend(handles=legend_elements, loc=spec_dict['loc'], fontsize=spec_dict['font']-6)\n",
    "\n",
    "# Set x-tick labels for models\n",
    "ax1.set_xticklabels(models1, rotation=spec_dict['rotation'])\n",
    "ax1.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "\n",
    "# Label the figure\n",
    "ax1.text(len(models), spec_dict['ylima'][1]-10, '$(A)$', fontsize=spec_dict['font'])\n",
    "\n",
    "# Save the image if needed\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7fca7-b494-4960-9e83-6568988dc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_v = [np.median(acc_dict[model]) for model in models]\n",
    "median_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852cdb6-bbe3-491a-8b1d-50d4f45af9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(acc_dict['shn0'])-np.mean(acc_dict['shn7db'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf8031-61f8-4c7d-9b18-8f386f51dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(acc_dict['shn7db'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6679727-b99e-41ca-8f5a-61e47a526635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(np.log(total_weights_v), median_v)\n",
    "\n",
    "adj_R2 = eegvislib.adjusted_R2(r_value, len(median_v), 1)\n",
    "\n",
    "# Print the results\n",
    "print(f' r({len(median_v)-2:.0f})={r_value:.2f}, p={p_value:.3f}, Adj. R^2={adj_R2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a61cf6-f318-4906-8b97-a69c1bb3dfa8",
   "metadata": {},
   "source": [
    "### Model Weights vs Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ff0cf-a9d6-4e0a-8dd9-0d567ee43336",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict['figname'] = 'modelVarEpochsvsWeight'\n",
    "spec_dict['title']   = \"Architecture Variation - Training Length\"\n",
    "spec_dict['color']   = ['tab:orange','tab:green']\n",
    "spec_dict['ylima']   = [-15, 200]\n",
    "patience = 15\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, \n",
    "                        figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "\n",
    "# Create a secondary y-axis for weights\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot weights on the secondary y-axis (ax2)\n",
    "ax2.plot(range(1, len(models) + 1), total_weights_v, color=spec_dict['color'][0], marker=spec_dict['markers'][0], \n",
    "         linestyle=spec_dict['linestyle'], linewidth=spec_dict['linew'], label='Weights')\n",
    "\n",
    "# Precompute n_epoch for each model\n",
    "n_epoch = {\n",
    "    model: [len(acc_train[model][i]) - patience + 1 for i in range(int(outerFolds*innerFolds))]\n",
    "    for model in models}\n",
    "\n",
    "# Boxplot for n_epoch\n",
    "box = ax1.boxplot([n_epoch[model] for model in models], labels=models, showfliers=False)\n",
    "\n",
    "# Remove median lines from the boxplot\n",
    "for median in box['medians']:\n",
    "    median.set_visible(False)\n",
    "\n",
    "# Scatter plot individual epoch values with slight random offsets on the x-axis\n",
    "for i, model in enumerate(models):\n",
    "    nepoch = n_epoch[model]\n",
    "    ax1.scatter(np.ones(len(nepoch)) * (i + 1) + spec_dict['jitter'] * np.random.randn(len(nepoch)), nepoch,\n",
    "                color='k', alpha=1, s=spec_dict['s'])\n",
    "\n",
    "# Label the first y-axis (for epochs)\n",
    "ax1.set_ylabel(\"Median $~N^{\\\\circ}$ Epochs\", color=spec_dict['color'][1], fontsize=spec_dict['font']-2)\n",
    "ax1.set_ylim(spec_dict['ylima'][0],spec_dict['ylima'][1])\n",
    "ax1.set_xlim(0.5, len(models) + 0.75)\n",
    "\n",
    "# Compute and plot the median values\n",
    "median_v = [np.median(n_epoch[model]) for model in models]\n",
    "for i, median in enumerate(median_v):\n",
    "    ax1.text(i + 1, spec_dict['ylima'][0]+2, f'{median:.0f}', ha='center', va='bottom', \n",
    "             color=spec_dict['color'][1], fontsize=spec_dict['font']-6, fontweight='bold')\n",
    "\n",
    "ax1.plot(np.arange(1, 1 + len(models)), median_v, marker=spec_dict['markers'][1], \n",
    "         linestyle=spec_dict['linestyle'], color=spec_dict['color'][1], linewidth=spec_dict['linew'])\n",
    "\n",
    "# Label the second y-axis (for weights)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel(\"$N^{\\\\circ}$ Trainable Parameters\", color=spec_dict['color'][0], fontsize=spec_dict['font']-2)\n",
    "ax2.set_ylim(spec_dict['ylimw'][0],spec_dict['ylimw'][1])\n",
    "\n",
    "# Add x-tick labels for models\n",
    "ax1.set_xticklabels(models1, rotation=spec_dict['rotation'])\n",
    "\n",
    "# Add title and other plot decorations\n",
    "ax1.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "ax1.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "\n",
    "# Create the legend\n",
    "legend_elements = [Line2D([0], [0], marker='.', color='k', label='Single Split', linestyle='None')]\n",
    "ax1.legend(handles=legend_elements, loc='upper center', fontsize=spec_dict['font']-6)\n",
    "\n",
    "# Annotate the plot with figure label\n",
    "ax1.text(len(models), spec_dict['ylime'][1]-20, '$(B)$', fontsize=spec_dict['font'])\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae522a43-85c0-4886-8056-74c7dbd4ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(np.log(total_weights_v), median_v)\n",
    "\n",
    "adj_R2 = eegvislib.adjusted_R2(r_value, len(median_v), 1)\n",
    "\n",
    "# Print the results\n",
    "print(f' r({len(median_v)-2:.0f})={r_value:.2f}, p={p_value:.3f}, Adj. R^2={adj_R2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a07d4d-8139-49c2-83b6-f49ea79d3409",
   "metadata": {},
   "source": [
    "## Analysis Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91bdf9-b313-480f-964a-5a6afb7f345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models      = ['shn0', 'shn5', 'shn6127', 'shn628', 'shn7db']\n",
    "\n",
    "spec_dict = {}\n",
    "spec_dict['models']     = ['ShallowNet', 'shn5', 'shn6$_{127}$', 'shn6$_{28}$', 'xEEGNet']\n",
    "spec_dict['listcolors'] = ['black','tab:brown', 'tab:red', 'tab:orange', 'tab:green']\n",
    "spec_dict['font']     = 16\n",
    "spec_dict['figname']  = 'lossCurves'\n",
    "spec_dict['linew']    = 0.5\n",
    "spec_dict['figdim']   = [10,6]\n",
    "spec_dict['titlet']   = 'Train Loss Curves'\n",
    "spec_dict['titlev']   = 'Validation Loss Curves'\n",
    "spec_dict['titlec']   = 'Correlation Train-Val Loss'\n",
    "spec_dict['loc']      = 'upper right'\n",
    "spec_dict['xlimt']    = [0.9, 300]\n",
    "spec_dict['ylimt']    = [0.0, 3.0]\n",
    "spec_dict['xlimv']    = [0.9, 300]\n",
    "spec_dict['ylimv']    = [0.5, None]\n",
    "spec_dict['xlimc']    = [-1,1]\n",
    "spec_dict['ylimc']    = [0,50]\n",
    "spec_dict['ytick']    = 5\n",
    "spec_dict['xtick']    = 0.2\n",
    "spec_dict['bin']      = 0.1\n",
    "spec_dict['rotation'] = 45\n",
    "\n",
    "acc_train = {}\n",
    "acc_val = {}\n",
    "# Precompute accuracy values for each model (only once)\n",
    "for model in models:\n",
    "    acct = []  # Reset accuracy list for each model\n",
    "    accv = []\n",
    "    for i in range(1, outerFolds+1):  # Loop over first parameter\n",
    "        for j in range(1, innerFolds+1):  # Loop over second parameter\n",
    "            file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "            filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "\n",
    "            # Load accuracy data from pickle file (avoid reloading for each iteration)\n",
    "            with open(resultsPath + filename + '.pickle', 'rb') as f:\n",
    "                shn = pickle.load(f)\n",
    "\n",
    "            # Append the accuracy to the list\n",
    "            acct.append(shn['training_loss_curve'])\n",
    "            accv.append(shn['validation_loss_curve'])\n",
    "\n",
    "    # Append the accuracy to the list\n",
    "    acc_train[model] = acct\n",
    "    acc_val[model] = accv\n",
    "\n",
    "fig = eegvislib.overfitting_inspection(models, acc_train, acc_val, spec_dict)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156d7c2-0b88-4ace-aac5-9a0548fc8913",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(eegvislib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f85c88-3438-442e-89ee-b1fdb40229ee",
   "metadata": {},
   "source": [
    "## Analysis Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474405ed-65b1-4a44-9166-0dc03cdc7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'shn7db'\n",
    "f_lim = [1,45]\n",
    "spec_dict = {'font':12,\n",
    "             'linew':1,\n",
    "             'cmap':'RdBu_r',\n",
    "             'bands': {'$\\\\delta$':  [0,4],\n",
    "                       '$\\\\theta$':  [4,8],\n",
    "                       '$\\\\alpha$':  [8,12],\n",
    "                       '$\\\\beta_1$': [12,16],\n",
    "                       '$\\\\beta_2$': [16,20],\n",
    "                       '$\\\\beta_3$': [20,28],\n",
    "                       '$\\\\gamma$': [28,f_lim[1]]},\n",
    "             'classlabels': classlabels,\n",
    "             'figdim': [4,1],\n",
    "             'plot_type': 'second',\n",
    "             'cmap': 'RdBu_r',\n",
    "             'figname': 'uniqueConfigDense'}\n",
    "\n",
    "spec_dict['xticks'] = [i for i in spec_dict['bands'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa8bad-23d5-402e-be22-4ab42bd902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_weights = []\n",
    "for i in range(1,outerFolds+1):\n",
    "    for j in range(1,innerFolds+1):\n",
    "        file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "        filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "        shn = torch.load(modelsPath + filename + '.pt')\n",
    "        fig, mask = eegvislib.denseweights_plot(shn,'Dense',spec_dict)\n",
    "        matrix_weights.append(mask)\n",
    "        plt.close()\n",
    "        \n",
    "matrix_count = {}\n",
    "# Count occurrences of each matrix\n",
    "for matrix in matrix_weights:\n",
    "    matrix_tuple = tuple(map(tuple, matrix))  # Convert to a hashable format\n",
    "    if matrix_tuple in matrix_count:\n",
    "        matrix_count[matrix_tuple] += 1\n",
    "    else:\n",
    "        matrix_count[matrix_tuple] = 1\n",
    "\n",
    "# Convert counts back to a list of matrices\n",
    "unique_matrices = [np.array(matrix) for matrix in matrix_count.keys()]\n",
    "counts = list(matrix_count.values())\n",
    "\n",
    "cmap = ListedColormap(['white', 'red', 'blue', 'green'])\n",
    "\n",
    "# Now you have a list of unique matrices\n",
    "fig, ax = plt.subplots(len(unique_matrices),1,\n",
    "                       figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]*len(unique_matrices)),\n",
    "                       constrained_layout=True)\n",
    "for i in range(len(unique_matrices)):\n",
    "    ax[i].set_title(f'Number of Splits with this config.: {counts[i]}', fontsize=spec_dict['font'])\n",
    "    ax[i].imshow(unique_matrices[i], aspect='auto', \n",
    "                 cmap=cmap, interpolation='nearest')\n",
    "    ax[i].set_yticks(np.arange(0, 3))\n",
    "    ax[i].set_yticklabels(labels=spec_dict['classlabels'], fontsize=spec_dict['font']-4)\n",
    "    ax[i].set_xticks(np.arange(0, len(spec_dict['xticks']), 1))\n",
    "    ax[i].set_xticklabels(spec_dict['xticks'], fontsize=spec_dict['font']-4)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d44c0-2a08-4e2d-853c-b911d3b71e78",
   "metadata": {},
   "source": [
    "## Analysis Statical Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d7dd7-29f2-4d14-a97a-609230ec7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load accuracy data for each model\n",
    "def load_accuracy_data(model, path, folds, task='alz', pipe='flt', srate='125', lr='000050', ch='019', w='004', metric='accuracy_weighted'):\n",
    "    acc = []\n",
    "    for i in range(folds[0][0], folds[0][1]+1):  # Loop over first parameter\n",
    "        for j in range(folds[1][0], folds[1][1]+1):  # Loop over second parameter\n",
    "            file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "            filename = f'{task}_{pipe}_{srate}_{model}_{file_suffix}_{lr}_{ch}_{w}'\n",
    "            with open(path + filename + '.pickle', 'rb') as f:\n",
    "                shn = pickle.load(f)\n",
    "            if isinstance(shn, dict):\n",
    "                acc.append(shn['accuracy_weighted'])\n",
    "            else:\n",
    "                acc.append(shn)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de358e-a8c3-4cdb-8b8f-49114fcff333",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "folds = [[1,outerFolds],[1,innerFolds]]\n",
    "task='alz'\n",
    "pipe='flt'\n",
    "srate='125'\n",
    "model = 'shn7db'\n",
    "lr='000050'\n",
    "ch='019'\n",
    "w='004'\n",
    "accMLRM = []\n",
    "accshnMLRM = []\n",
    "path = numericPath + 'StatisticalModels' + sep + 'Results' + sep\n",
    "for i in range(folds[0][0], folds[0][1]+1):  # Loop over first parameter\n",
    "    for j in range(folds[1][0], folds[1][1]+1):  # Loop over second parameter\n",
    "        file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "        filename = f'{task}_{pipe}_{srate}_{model}_{file_suffix}_{lr}_{ch}_{w}'\n",
    "        with open(path + filename + '.pickle', 'rb') as f:\n",
    "            shn = pickle.load(f)\n",
    "        accMLRM.append(shn['MLRM_accuracy_weighted'])\n",
    "        accshnMLRM.append(shn['shnMLRM_accuracy_weighted'])\n",
    "\n",
    "metrics['MLRM'] = accMLRM\n",
    "metrics['shnMLRM'] = accshnMLRM\n",
    "\n",
    "model = 'shn7db'\n",
    "path = resultsPath\n",
    "metrics['shn7db'] = load_accuracy_data(model, resultsPath, [[1,outerFolds],[1,innerFolds]])\n",
    "\n",
    "model = 'shn0'\n",
    "path = resultsPath\n",
    "metrics['shn0'] = load_accuracy_data(model, resultsPath, [[1,outerFolds],[1,innerFolds]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae802a4-b145-4473-871f-83e277a856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = {'figdim': [7,5],\n",
    "             'jitter': 0.02,\n",
    "             's': 5,\n",
    "             'font': 16,\n",
    "             'rotation': 45,\n",
    "             'xticks': ['MLRM', 'shnMLRM', 'xEEGNet', 'ShallowNet'],\n",
    "             'ylim': [20,105],\n",
    "             'linew':2,\n",
    "             'accrandom': 1/len(classlabels),\n",
    "             'marker': 'o',\n",
    "             'linestyle': '--',\n",
    "             'color': 'tab:blue',\n",
    "             'loc': 'upper center',\n",
    "             'figname': 'statModelComparison'}\n",
    "\n",
    "def stat_comparison(metrics, spec_dict):\n",
    "    df = pd.DataFrame(metrics)*100\n",
    "    # Plot setup\n",
    "    fig, ax = plt.subplots(figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "    \n",
    "    box = ax.boxplot(df, showfliers=False, widths=0.6, medianprops=dict(color=\"none\"))\n",
    "    # Add jittered scatter points\n",
    "    for i, col in enumerate(df.columns, start=1):\n",
    "        jittered_x = np.random.normal(i, spec_dict['jitter'], size=len(df[col]))\n",
    "        ax.scatter(jittered_x, df[col], color='black', alpha=1, s=spec_dict['s'])\n",
    "    \n",
    "    # Set labels and ticks\n",
    "    ax.set_ylabel('Median Weighted Accuracy %', fontsize=spec_dict['font']-2, color='tab:blue')\n",
    "    ax.set_xticks(range(1, len(df.columns) + 1))\n",
    "    ax.set_xticklabels(spec_dict['xticks'], rotation=spec_dict['rotation'], fontsize=spec_dict['font']-4)\n",
    "    ax.set_ylim(spec_dict['ylim'][0], spec_dict['ylim'][1])\n",
    "    ax.axhline(spec_dict['accrandom']*100, linestyle='--', linewidth=spec_dict['linew'], color='red')\n",
    "    ax.set_title(\"Comparison with Multinomial Logistic Regression\", fontsize=spec_dict['font'])\n",
    "    \n",
    "    # Display median values and connect them with a line\n",
    "    medians = [np.median(df[col]) for col in df.columns]\n",
    "    for i, median in enumerate(medians, start=1):\n",
    "        ax.text(i, spec_dict['ylim'][0]+2, f'{median:.1f}%', ha='center', va='bottom',\n",
    "                color=spec_dict['color'], fontsize=spec_dict['font']-6, fontweight='bold')\n",
    "    ax.plot(range(1, len(medians) + 1), medians, marker=spec_dict['marker'], \n",
    "            linestyle=spec_dict['linestyle'], color=spec_dict['color'], linewidth=spec_dict['linew'])\n",
    "    \n",
    "    # Custom legend\n",
    "    legend_elements = [Line2D([0], [0], marker='.', color='k', label='Single Split', linestyle='None'),\n",
    "                       Line2D([0], [0], label=f'{spec_dict['accrandom']:.0%} Random Guess', linestyle=spec_dict['linestyle'],\n",
    "                              linewidth=spec_dict['linew'], color='red')\n",
    "                      ]\n",
    "    \n",
    "    ax.legend(handles=legend_elements, loc=spec_dict['loc'], fontsize=spec_dict['font']-6)\n",
    "    return fig\n",
    "\n",
    "fig = stat_comparison(metrics, spec_dict)\n",
    "# Save and display\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff96568-6418-4f32-b09b-eaf2ff6dc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ np.mean(i) for i in metrics.values()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
