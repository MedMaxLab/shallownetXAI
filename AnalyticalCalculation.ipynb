{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad69f38-cf63-4652-b9e1-a502e079a38d",
   "metadata": {},
   "source": [
    "# Analytical Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac6c09-2510-46e5-89a6-69dc283ffc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import importlib\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.stats import multitest\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "from collections import defaultdict\n",
    "from scipy.stats import linregress\n",
    "import torch\n",
    "from AllFnc import eegvislib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "\n",
    "# SET PATH\n",
    "sep         = os.path.sep\n",
    "dataPath    = '/data/delpup/datasets/eegpickle/'\n",
    "osPath      = os.path.abspath(os.getcwd())\n",
    "imgPath     = osPath + sep + 'imgs' + sep\n",
    "modelsPath  = osPath + sep + 'AlzClassification' + sep + 'Models' + sep\n",
    "resultsPath = osPath + sep + 'AlzClassification' + sep + 'Results' + sep\n",
    "numericPath = osPath + sep + 'AnalyticalCalculation' + sep\n",
    "\n",
    "# IMGS OPTIONS\n",
    "imgs_format = '.pdf'\n",
    "save_img    = True\n",
    "\n",
    "outerFolds  = 10\n",
    "innerFolds  = 5\n",
    "classlabels = ['CTL', 'FTD', 'AD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba04fe8-43e9-4c1e-84d6-5603c49e6ca9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis First Layer Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a27a31-3e3f-4943-9476-ce807573594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_change_load(path, split, mod, model, metric):\n",
    "    \"\"\"\n",
    "    Load weight change data and a specific performance metric from pickle files.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path (str): Directory path for the model files.\n",
    "    - split (tuple): Tuple specifying outer and inner folds as (outerFold, innerFold).\n",
    "    - mod (str): Modifier string to identify the file.\n",
    "    - model (str): Model identifier.\n",
    "    - metric (str): Performance metric to load.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    - dw (numpy.ndarray): Flattened weight change array scaled by 100.\n",
    "    - bacc (float): Performance metric value scaled by 100.\n",
    "    \"\"\"\n",
    "    outerFold, innerFold = split\n",
    "\n",
    "    # Load and process weight change data\n",
    "    with open(f'{path}{model}_dw_{outerFold}_{innerFold}_{mod}.pkl', 'rb') as file:\n",
    "        dw_preinit = pickle.load(file)\n",
    "    dw = np.ravel(dw_preinit.numpy()) * 100  # Flatten and scale\n",
    "\n",
    "    # Load and process performance metric data\n",
    "    with open(f'{path}{model}_scores_{outerFold}_{innerFold}_{mod}.pkl', 'rb') as file:\n",
    "        bacc = pickle.load(file)[metric]\n",
    "    bacc *= 100  # Scale the performance metric\n",
    "\n",
    "    return dw, bacc\n",
    "\n",
    "def weight_change_plot(path, mod, model, splits, spec_dict):\n",
    "    \"\"\"\n",
    "    Plot the histogram of weight changes across specified splits.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - path (str): Folder to path used by the function weight_change_load.\n",
    "    - mod (str): Modifier string to identify the file.\n",
    "    - model (str): Model identifier.\n",
    "    - splits (list): List of split tuples [(outerFold1, innerFold1), (outerFold2, innerFold2), ...].\n",
    "    - spec_dict (dict): A dictionary containing various specification parameters \n",
    "    and other plotting configurations.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    - fig (matplotlib.figure.Figure): The generated plot figure.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "    ax.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "\n",
    "    for split in splits:\n",
    "        # Load metrics for each split\n",
    "        dw_random, bacc_random = weight_change_load(path, split, mod, model, spec_dict['metric'])\n",
    "        \n",
    "        # Clip weight change values to specified limits\n",
    "        dw_random = np.clip(dw_random, -spec_dict['clip'], spec_dict['clip'])\n",
    "\n",
    "        # Compute histogram counts and relative frequencies\n",
    "        counts, bin_edges = np.histogram(dw_random, bins=spec_dict['bins'])\n",
    "        relative_counts = counts * 100 / len(dw_random)  # Convert to percentage\n",
    "\n",
    "        # Plot histogram as a bar chart with relative counts\n",
    "        ax.bar(bin_edges[:-1], relative_counts, width=np.diff(bin_edges), alpha=spec_dict['alpha'],\n",
    "               label=f'Split {split[0]}-{split[1]}', align='edge')\n",
    "\n",
    "    # Set axis labels and customize ticks\n",
    "    ax.set_ylabel('Relative Count %', fontsize=spec_dict['font'] - 2)\n",
    "    ax.set_xlabel(r'$\\Delta_{w\\%} = (w - w_{init})/|w|$', fontsize=spec_dict['font'] - 2)\n",
    "    ax.set_xlim(-spec_dict['clip'], spec_dict['clip'])\n",
    "    ax.set_xticks(np.arange(-spec_dict['clip'], spec_dict['clip'] + spec_dict['ticks'][0], spec_dict['ticks'][0]))\n",
    "    ax.set_yticks(np.arange(0, np.max(relative_counts) + spec_dict['ticks'][1], spec_dict['ticks'][1]))\n",
    "    ax.tick_params(axis='both', labelsize=spec_dict['font'] - 4)\n",
    "    ax.legend(loc=spec_dict['loc'], fontsize=spec_dict['font'] - 6)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1060e-3ddf-4067-8ba2-126040c515ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parameters\n",
    "mod = 'random'\n",
    "model = 'shn0'\n",
    "splits = [[9, 2], [6, 5]]\n",
    "spec_dict = {\n",
    "    'font': 16,\n",
    "    'clip': 50,\n",
    "    'bins': 40,\n",
    "    'alpha': 0.5,\n",
    "    'ticks': [10, 2],\n",
    "    'title': 'Weights Change in the First Layer ShallowNet',\n",
    "    'figdim': [7, 5],\n",
    "    'loc': 'upper right',\n",
    "    'metric': 'accuracy_weighted',\n",
    "    'filename': 'weightChangeFirstLayer'\n",
    "}\n",
    "\n",
    "# Generate and optionally save the plot\n",
    "fig = weight_change_plot(numericPath + 'Initialization' + sep, mod, model, splits, spec_dict)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['filename'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad008d-5684-4237-9319-7e010535bf9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis Topographies Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7773a64-ba79-4a2b-bc87-804a6fb0011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvals_calculation(scalps, indexs, spec_dict):\n",
    "    \"\"\"\n",
    "    Calculate the pairwise p-values and correlation statistics between filter activations across specified scalp maps.\n",
    "    Adjusts p-values for multiple comparisons and returns the corrected p-value matrix and a significance matrix.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - scalps (list of np.ndarray): List of 4D arrays representing the scalp maps. \n",
    "    Each array should have a shape (filters, kernels=1, hight=channels, width=1)    \n",
    "    - indexs (list of int): Indices for two specific scalp maps in `scalps` to compare.\n",
    "    - spec_dict (dict): A dictionary containing various specification parameters \n",
    "    and other plotting configurations.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    - corrected_pvals (np.ndarray): Symmetric matrix of corrected p-values for the pairwise filter comparisons.\n",
    "    - significance_matrix (np.ndarray): Boolean matrix indicating where p-values are significant after correction.\n",
    "    - stats (np.ndarray): Symmetric matrix of pearson coefficients for the pairwise filter comparisons.\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = scalps[0].shape[0]  # Number of filters in each scalp map\n",
    "    pvals = np.zeros((filters, filters))  # Matrix to store p-values\n",
    "    stats = np.zeros((filters, filters))  # Matrix to store correlation statistics\n",
    "\n",
    "    # Calculate pairwise Pearson correlations between filters in specified scalp maps\n",
    "    for i in range(filters):\n",
    "        for j in range(filters):\n",
    "            res = pearsonr(scalps[indexs[0]][i, 0, :, 0], scalps[indexs[1]][j, 0, :, 0])\n",
    "            pvals[i, j] = res.pvalue\n",
    "            stats[i, j] = res.statistic\n",
    "\n",
    "    # Extract the upper triangle of p-values for multiple testing correction\n",
    "    upper_tri_indices = np.triu_indices(filters)\n",
    "    flattened_pvals = pvals[upper_tri_indices].flatten()\n",
    "\n",
    "    # Apply multiple testing correction (e.g., Bonferroni, FDR)\n",
    "    corrected_res = multitest.multipletests(flattened_pvals, alpha=spec_dict['pval'], method=spec_dict['method'])\n",
    "    corrected_pvals_flat = corrected_res[1]  # Corrected p-values\n",
    "    significance_matrix_flat = corrected_res[0]  # Boolean array for significance\n",
    "\n",
    "    # Reconstruct matrices with corrected p-values and significance flags in original dimensions\n",
    "    corrected_pvals = np.zeros((filters, filters))\n",
    "    significance_matrix = np.zeros((filters, filters), dtype=bool)\n",
    "\n",
    "    # Map corrected values to the upper triangle\n",
    "    corrected_pvals[upper_tri_indices] = corrected_pvals_flat\n",
    "    significance_matrix[upper_tri_indices] = significance_matrix_flat\n",
    "\n",
    "    # Reflect upper triangle to lower triangle for symmetry\n",
    "    corrected_pvals = corrected_pvals + corrected_pvals.T - np.diag(np.diag(corrected_pvals))\n",
    "    significance_matrix = significance_matrix | significance_matrix.T\n",
    "\n",
    "    return corrected_pvals, significance_matrix, stats\n",
    "\n",
    "\n",
    "def pvals_plot(corrected_pvals, significance_matrix, stats, splits, indexs, spec_dict):\n",
    "    \"\"\"\n",
    "    Plot the significance matrix with annotated corrected p-values for significant comparisons.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    - corrected_pvals (np.ndarray): Symmetric matrix of corrected p-values for filter comparisons.\n",
    "    - significance_matrix (np.ndarray): Boolean matrix indicating where p-values are significant.\n",
    "    - stats (np.ndarray): Symmetric matrix of pearson coefficients for the pairwise filter comparisons.\n",
    "    - splits (list of lists): List of split identifiers. \n",
    "    Each identifier is a list of integers representing the split structure.\n",
    "    - indexs (list of int): Indices for two specific scalp maps from `splits` to label in the plot.\n",
    "    - spec_dict (dict): A dictionary containing various specification parameters \n",
    "    and other plotting configurations.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    fig (matplotlib.figure.Figure): The resulting figure with the significance matrix plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    filters = np.shape(corrected_pvals)[0]  # Number of filters\n",
    "\n",
    "    # Initialize plot\n",
    "    fig, ax = plt.subplots(figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "    ax.imshow(significance_matrix, cmap='Greys')  # Display significance matrix\n",
    "    ax.set_ylabel(f'Split {splits[indexs[0]][0]}-{splits[indexs[0]][1]}', fontsize=spec_dict['font']-2)\n",
    "    ax.set_xlabel(f'Split {splits[indexs[1]][0]}-{splits[indexs[1]][1]}', fontsize=spec_dict['font']-2)\n",
    "    ax.set_xticks(np.arange(0, filters, 1))\n",
    "    ax.set_xticklabels(spec_dict['xticks'], fontsize=spec_dict['font']-4)\n",
    "    ax.set_yticks(np.arange(0, filters, 1))\n",
    "    ax.set_yticklabels(spec_dict['xticks'], fontsize=spec_dict['font']-4)\n",
    "    ax.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "\n",
    "    # Annotate significant p-values on the plot\n",
    "    for i in range(filters):\n",
    "        for j in range(filters):\n",
    "            if significance_matrix[i, j]:  # Only annotate cells with significant p-values\n",
    "                adj_R2 = eegvislib.adjusted_R2(stats[i,j], spec_dict['C'], 1)\n",
    "                ax.text(j, i, f'p$={corrected_pvals[i, j]:.1e}$ \\n $\\\\rho({spec_dict['C']})={stats[i,j]:.2f}$ \\n adj.$R^2={adj_R2:.2f}$', \n",
    "                        ha='center', va='center', color='white', fontsize=spec_dict['font']-8)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a17b5a-b8eb-46ac-8399-7aa5448076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [[9, 2], [6, 5]]\n",
    "modelsToimport = ['alz_flt_125_shn7db_009_002_000050_019_004','alz_flt_125_shn7db_006_005_000050_019_004']\n",
    "\n",
    "spec_dict = {'pval': 0.05,\n",
    "             'method': 'holm',\n",
    "             'xticks': ['$\\\\delta$', '$\\\\theta$', '$\\\\alpha$', '$\\\\beta_1$',\n",
    "                       '$\\\\beta_2$', '$\\\\beta_3$', '$\\\\gamma$'],\n",
    "             'C': 19,\n",
    "             'title': f'Significance Correlation (Holm corrected)',\n",
    "             'font': 16,\n",
    "             'figdim': [7, 7]}\n",
    "\n",
    "scalps = []\n",
    "for modelToimport in modelsToimport:\n",
    "    shnm = torch.load(modelsPath + modelToimport + '.pt')    \n",
    "    scalps.append(shnm['encoder.conv2.weight'].numpy())\n",
    "\n",
    "corrected_pvals, significance_matrix, stats = pvals_calculation(scalps, [0,1], spec_dict)\n",
    "fig = pvals_plot(corrected_pvals, significance_matrix, stats, splits, [0,1], spec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c47d45-161c-44be-b95e-dfdedde79449",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_pvals, significance_matrix, stats = pvals_calculation(scalps, [0,0], spec_dict)\n",
    "fig = pvals_plot(corrected_pvals, significance_matrix, stats, splits, [0,0], spec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc4e9f-d7af-4c2d-adcd-2e0110c9b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_pvals, significance_matrix, stats = pvals_calculation(scalps, [1,1], spec_dict)\n",
    "fig = pvals_plot(corrected_pvals, significance_matrix, stats, splits, [1,1], spec_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4b142-c3b2-438b-bd81-70e131ea8ea0",
   "metadata": {},
   "source": [
    "## Analysis Overlap Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59beb8-878b-45d8-9c49-4bebb34164a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'shn7db'\n",
    "overlap_trainval  = []\n",
    "overlap_traintest = [] \n",
    "overlap_valtest   = []\n",
    "area_train = []\n",
    "area_val = []\n",
    "area_test = []\n",
    "acc = []\n",
    "for i in range(1,outerFolds+1):\n",
    "    for j in range(1,innerFolds+1):\n",
    "        file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "        filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "        with open(numericPath + 'Overlap' +sep + 'Results' +sep + filename + '.pickle', 'rb') as f:\n",
    "            shn = pickle.load(f)\n",
    "        overlap_traintest.append(shn[0])\n",
    "        overlap_trainval.append(shn[1])\n",
    "        overlap_valtest.append(shn[2])\n",
    "        area_train.append(shn[3])\n",
    "        area_val.append(shn[4])\n",
    "        area_test.append(shn[5])\n",
    "        with open(resultsPath + filename + '.pickle', 'rb') as f:\n",
    "            shnR = pickle.load(f)\n",
    "        acc.append(shnR['accuracy_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28577b-11be-4e2a-b072-e3f53b0bba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to analyze\n",
    "variables = {\n",
    "    \"overlap_traintest\": overlap_traintest,\n",
    "    \"overlap_trainval\": overlap_trainval,\n",
    "    \"overlap_valtest\": overlap_valtest,\n",
    "    \"area_train\": area_train,\n",
    "    \"area_val\": area_val,\n",
    "    \"area_test\": area_test,\n",
    "}\n",
    "\n",
    "# Step 1: Calculate pairwise correlations and p-values\n",
    "pairs = []\n",
    "corrs = []\n",
    "p_values = []\n",
    "\n",
    "keys = list(variables.keys())\n",
    "for i, key1 in enumerate(keys):\n",
    "    for j, key2 in enumerate(keys):\n",
    "        if i < j:  # Avoid duplicate pairs and self-correlation\n",
    "            corr, p_val = spearmanr(variables[key1], variables[key2])\n",
    "            pairs.append((key1, key2))\n",
    "            corrs.append(corr)\n",
    "            p_values.append(p_val)\n",
    "\n",
    "# Step 2: Apply Holm-Bonferroni correction\n",
    "corrected_res = multitest.multipletests(p_values, method='holm')\n",
    "\n",
    "# Step 3: Identify pairs with corrected p-values > 0.05\n",
    "uncorrelated_pairs = [\n",
    "    pairs[i] for i, p_val in enumerate(corrected_res[0]) if p_val > 0.05\n",
    "]\n",
    "\n",
    "# Identify uncorrelated variables\n",
    "uncorrelated_vars = set()\n",
    "for pair in uncorrelated_pairs:\n",
    "    uncorrelated_vars.update(pair)\n",
    "uncorrelated_vars = list(uncorrelated_vars)\n",
    "\n",
    "print(\"Uncorrelated variable pairs (Holm-Bonferroni corrected p > 0.05):\")\n",
    "for pair in uncorrelated_pairs:\n",
    "    print(pair)\n",
    "\n",
    "print(\"\\nIndependent variables after correction:\")\n",
    "print(uncorrelated_vars)\n",
    "\n",
    "# Step 4: Regression Analysis\n",
    "# Prepare feature matrix with uncorrelated variables\n",
    "X_features = np.column_stack([variables[var] for var in uncorrelated_vars])\n",
    "X_features = sm.add_constant(X_features)\n",
    "y = acc  # Target variable\n",
    "\n",
    "# Fit the regression model\n",
    "model = sm.OLS(y, X_features)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the regression summary\n",
    "print(\"\\nRegression Results:\")\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6191af-ab3f-467c-bf07-6d6d5ef49123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "formula = \"acc ~ area_test + overlap_traintest + area_test*overlap_traintest\"\n",
    "\n",
    "# Step 4: Fit the model using the formula\n",
    "model = smf.ols(formula=formula, data=pd.DataFrame(variables)).fit()\n",
    "print(\"\\nRegression Results:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055ca09-3e62-4549-abfe-ebce24010012",
   "metadata": {},
   "source": [
    "## Analysis Model Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b434f33-7e61-48f9-8ffe-0d37fb42a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"shn0\", \"shn1\", \"shn2\", \"shn3\", \"shn4\", \"shn5\", \"shn67\",\n",
    "          \"shn628\",\"shn663\",\"shn6119\",\"shn6126\",\"shn6127\",\"shn7\",\"shn7db\"]\n",
    "\n",
    "# Set of models for which a specific condition applies\n",
    "model_set = {'shn0', 'shn1', 'shn2', 'shn3'} #These models has not the first layer frozen\n",
    "\n",
    "spec_dict = {'figname': 'modelVarAccvsWeight',\n",
    "             'font': 18,\n",
    "             'linew': 2,\n",
    "             's':4,\n",
    "             'rotation': 45,\n",
    "             'loc': 'upper center',\n",
    "             'title': 'Architecture Variation - Performance',\n",
    "             'accrandom': 1/len(classlabels),\n",
    "             'linestyle': '--',\n",
    "             'markers': ['X','o'],\n",
    "             'ylima': [20,105],\n",
    "             'ylimw': [10**1,10**6],\n",
    "             'jitter': 0.02,\n",
    "             'figdim': [15,5],\n",
    "             'color': ['tab:orange','tab:blue']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236a44d-e8f2-4e75-8afe-a0389fb2bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each model\n",
    "total_weights_v = []\n",
    "for model in models:\n",
    "    filename = f'alz_flt_125_{model}_001_001_000050_019_004'\n",
    "    shn = torch.load(modelsPath + filename + '.pt')\n",
    "\n",
    "    total_weights = 0\n",
    "    # Iterate through the state_dict (model weights)\n",
    "    for key, tensor in shn.items():\n",
    "        # Skip specific keys related to batch normalization\n",
    "        if key in ['encoder.batch1.running_mean', 'encoder.batch1.running_var', 'encoder.batch1.num_batches_tracked']:\n",
    "            continue\n",
    "        \n",
    "        # Add the tensor's total number of elements, applying conditions for specific models\n",
    "        if model in model_set:\n",
    "            total_weights += tensor.numel()\n",
    "        elif key not in ['encoder.conv1.weight', 'encoder.conv1.bias']:\n",
    "            total_weights += tensor.numel()\n",
    "    \n",
    "    total_weights_v.append(total_weights)\n",
    "\n",
    "sorted_pairs = sorted(zip(total_weights_v, models))\n",
    "stored = sorted_pairs[0]\n",
    "sorted_pairs[0] = sorted_pairs[1]\n",
    "sorted_pairs[1] = stored\n",
    "\n",
    "# Unzip the sorted pairs to get sorted vector1\n",
    "models = [v for _, v in sorted_pairs]\n",
    "total_weights_v = [v for v, _ in sorted_pairs]\n",
    "\n",
    "models1 = [sorted_pairs[i][1] for i in range(len(models))]\n",
    "models1[9] = 'ShallowNet'\n",
    "models1[0] = 'Med-ShallowNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9ae6d-a775-4cfb-b138-aeb380fa6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = defaultdict(list)\n",
    "acc_train = {}\n",
    "acc_val = {}\n",
    "# Precompute accuracy values for each model (only once)\n",
    "for model in models:\n",
    "    acct = []  # Reset accuracy list for each model\n",
    "    accv = []\n",
    "    for i in range(1, outerFolds+1):  # Loop over first parameter\n",
    "        for j in range(1, innerFolds+1):  # Loop over second parameter\n",
    "            file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "            filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "\n",
    "            # Load accuracy data from pickle file (avoid reloading for each iteration)\n",
    "            with open(resultsPath + filename + '.pickle', 'rb') as f:\n",
    "                shn = pickle.load(f)\n",
    "\n",
    "            # Append the accuracy to the list\n",
    "            acc_dict[model].append(shn['accuracy_weighted'] * 100)\n",
    "            acct.append(shn['training_loss_curve'])\n",
    "            accv.append(shn['validation_loss_curve'])\n",
    "\n",
    "    # Append the accuracy to the list\n",
    "    acc_train[model] = acct\n",
    "    acc_val[model] = accv\n",
    "    print(f'{model} QCV: {eegvislib.quartile_coefficient_of_variation(acc_dict[model]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b3cc7-a409-4a80-b8a5-4940d301ed4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model Weights vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da635e1e-6681-4ddd-9287-d42d544e6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, \n",
    "                        figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot the weights vs models (on the second y-axis, ax2)\n",
    "ax2.plot(range(1, len(models) + 1), total_weights_v, color=spec_dict['color'][0], \n",
    "         marker=spec_dict['markers'][0], linestyle=spec_dict['linestyle'], \n",
    "         linewidth=spec_dict['linew'], label='Weights')\n",
    "\n",
    "# Plot boxplots for all models (on the first y-axis, ax1)\n",
    "box = ax1.boxplot(list(acc_dict.values()), showfliers=False)\n",
    "\n",
    "# Remove median line from boxplot (using more efficient approach)\n",
    "for median in box['medians']:\n",
    "    median.set_visible(False)\n",
    "\n",
    "# Add scatter points (individual accuracy values) for each model\n",
    "for i, model in enumerate(models):\n",
    "    acc = acc_dict[model]\n",
    "    ax1.scatter(np.ones(len(acc)) * (i + 1) + spec_dict['jitter']*np.random.randn(len(acc)), acc,\n",
    "                color='k', alpha=1, s=spec_dict['s'])\n",
    "\n",
    "# Label the first y-axis (for accuracies)\n",
    "ax1.set_ylabel(\"Median Weighted Accuracy %\", color=spec_dict['color'][1], fontsize=spec_dict['font']-2)\n",
    "ax1.set_ylim(spec_dict['ylima'][0], spec_dict['ylima'][1])\n",
    "ax1.set_xlim(0.5, len(models) + 0.75)\n",
    "\n",
    "# Plot the median value as text on the boxplot for each model\n",
    "median_v = [np.median(acc_dict[model]) for model in models]\n",
    "for i, median in enumerate(median_v):\n",
    "    ax1.text(i + 1, spec_dict['ylima'][0]+2, f'{median:.1f}%', ha='center', va='bottom', \n",
    "             color=spec_dict['color'][1], fontsize=spec_dict['font']-6, fontweight='bold')\n",
    "\n",
    "ax1.plot(np.arange(1, 1 + len(models)), median_v, marker=spec_dict['markers'][1], linestyle=spec_dict['linestyle'],\n",
    "         color=spec_dict['color'][1], linewidth=spec_dict['linew'])\n",
    "\n",
    "# Label the second y-axis (for weights)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel(\"$N^{\\\\circ}$ Trainable Parameters\", color=spec_dict['color'][0], fontsize=spec_dict['font']-2)\n",
    "ax2.set_ylim(spec_dict['ylimw'][0], spec_dict['ylimw'][1])\n",
    "\n",
    "# Add a horizontal line at 33.33 for reference\n",
    "ax1.axhline(spec_dict['accrandom']*100, linestyle=spec_dict['linestyle'], linewidth=spec_dict['linew'], color='red')\n",
    "\n",
    "# Add a title to the plot\n",
    "ax1.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "\n",
    "# Create legend\n",
    "legend_elements = [Line2D([0], [0], marker='.', color='k', label='Single Split', linestyle='None'),\n",
    "                   Line2D([0], [0], label=f'{spec_dict['accrandom']:.0%} Random Guess', \n",
    "                          linestyle=spec_dict['linestyle'], linewidth=spec_dict['linew'], color='red')]\n",
    "ax1.legend(handles=legend_elements, loc=spec_dict['loc'], fontsize=spec_dict['font']-6)\n",
    "\n",
    "# Set x-tick labels for models\n",
    "ax1.set_xticklabels(models1, rotation=spec_dict['rotation'])\n",
    "ax1.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "\n",
    "# Label the figure\n",
    "ax1.text(len(models), spec_dict['ylima'][1]-10, '$(A)$', fontsize=spec_dict['font'])\n",
    "\n",
    "# Save the image if needed\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6679727-b99e-41ca-8f5a-61e47a526635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(np.log(total_weights_v), median_v)\n",
    "\n",
    "adj_R2 = eegvislib.adjusted_R2(r_value, len(median_v), 1)\n",
    "\n",
    "# Print the results\n",
    "print(f' r({len(median_v)-2:.0f})={r_value:.2f}, p={p_value:.3f}, Adj. R^2={adj_R2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a61cf6-f318-4906-8b97-a69c1bb3dfa8",
   "metadata": {},
   "source": [
    "### Model Weights vs Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ff0cf-a9d6-4e0a-8dd9-0d567ee43336",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict['figname'] = 'modelVarEpochsvsWeight'\n",
    "spec_dict['title']   = \"Architecture Variation - Training Length\"\n",
    "spec_dict['color']   = ['tab:orange','tab:green']\n",
    "spec_dict['ylime']   = [-15, 200]\n",
    "patience = 15\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, \n",
    "                        figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "\n",
    "# Create a secondary y-axis for weights\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot weights on the secondary y-axis (ax2)\n",
    "ax2.plot(range(1, len(models) + 1), total_weights_v, color=spec_dict['color'][0], marker=spec_dict['markers'][0], \n",
    "         linestyle=spec_dict['linestyle'], linewidth=spec_dict['linew'], label='Weights')\n",
    "\n",
    "# Precompute n_epoch for each model\n",
    "n_epoch = {\n",
    "    model: [len(acc_train[model][i]) - patience + 1 for i in range(int(outerFolds*innerFolds))]\n",
    "    for model in models}\n",
    "\n",
    "# Boxplot for n_epoch\n",
    "box = ax1.boxplot([n_epoch[model] for model in models], labels=models, showfliers=False)\n",
    "\n",
    "# Remove median lines from the boxplot\n",
    "for median in box['medians']:\n",
    "    median.set_visible(False)\n",
    "\n",
    "# Scatter plot individual epoch values with slight random offsets on the x-axis\n",
    "for i, model in enumerate(models):\n",
    "    nepoch = n_epoch[model]\n",
    "    ax1.scatter(np.ones(len(nepoch)) * (i + 1) + spec_dict['jitter'] * np.random.randn(len(nepoch)), nepoch,\n",
    "                color='k', alpha=1, s=spec_dict['s'])\n",
    "\n",
    "# Label the first y-axis (for epochs)\n",
    "ax1.set_ylabel(\"Median $~N^{\\\\circ}$ Epochs\", color=spec_dict['color'][1], fontsize=spec_dict['font']-2)\n",
    "ax1.set_ylim(spec_dict['ylime'][0],spec_dict['ylime'][1])\n",
    "ax1.set_xlim(0.5, len(models) + 0.75)\n",
    "\n",
    "# Compute and plot the median values\n",
    "median_v = [np.median(n_epoch[model]) for model in models]\n",
    "for i, median in enumerate(median_v):\n",
    "    ax1.text(i + 1, spec_dict['ylime'][0]+2, f'{median:.0f}', ha='center', va='bottom', \n",
    "             color=spec_dict['color'][1], fontsize=spec_dict['font']-6, fontweight='bold')\n",
    "\n",
    "ax1.plot(np.arange(1, 1 + len(models)), median_v, marker=spec_dict['markers'][1], \n",
    "         linestyle=spec_dict['linestyle'], color=spec_dict['color'][1], linewidth=spec_dict['linew'])\n",
    "\n",
    "# Label the second y-axis (for weights)\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel(\"$N^{\\\\circ}$ Trainable Parameters\", color=spec_dict['color'][0], fontsize=spec_dict['font']-2)\n",
    "ax2.set_ylim(spec_dict['ylimw'][0],spec_dict['ylimw'][1])\n",
    "\n",
    "# Add x-tick labels for models\n",
    "ax1.set_xticklabels(models1, rotation=spec_dict['rotation'])\n",
    "\n",
    "# Add title and other plot decorations\n",
    "ax1.set_title(spec_dict['title'], fontsize=spec_dict['font'])\n",
    "ax1.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=spec_dict['font']-4)\n",
    "\n",
    "# Create the legend\n",
    "legend_elements = [Line2D([0], [0], marker='.', color='k', label='Single Split', linestyle='None')]\n",
    "ax1.legend(handles=legend_elements, loc='upper center', fontsize=spec_dict['font']-6)\n",
    "\n",
    "# Annotate the plot with figure label\n",
    "ax1.text(len(models), spec_dict['ylime'][1]-20, '$(B)$', fontsize=spec_dict['font'])\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae522a43-85c0-4886-8056-74c7dbd4ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(np.log(total_weights_v), median_v)\n",
    "\n",
    "adj_R2 = eegvislib.adjusted_R2(r_value, len(median_v), 1)\n",
    "\n",
    "# Print the results\n",
    "print(f' r({len(median_v)-2:.0f})={r_value:.2f}, p={p_value:.3f}, Adj. R^2={adj_R2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a07d4d-8139-49c2-83b6-f49ea79d3409",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Analysis Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a91bdf9-b313-480f-964a-5a6afb7f345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models      = ['shn0', 'shn5', 'shn6127', 'shn628', 'shn7db']\n",
    "\n",
    "spec_dict = {}\n",
    "spec_dict['models']     = ['ShallowNet', 'shn5', 'shn6$_{127}$', 'shn6$_{28}$', 'Med-ShallowNet']\n",
    "spec_dict['listcolors'] = ['black','tab:brown', 'tab:red', 'tab:orange', 'tab:green']\n",
    "spec_dict['font']     = 16\n",
    "spec_dict['figname']  = 'lossCurves'\n",
    "spec_dict['linew']    = 0.5\n",
    "spec_dict['figdim']   = [10,6]\n",
    "spec_dict['titlet']   = 'Train Loss Curves'\n",
    "spec_dict['titlev']   = 'Validation Loss Curves'\n",
    "spec_dict['titlec']   = 'Correlation Train-Val Loss'\n",
    "spec_dict['loc']      = 'upper right'\n",
    "spec_dict['xlimt']    = [0.9, 300]\n",
    "spec_dict['ylimt']    = [0.0, 3.0]\n",
    "spec_dict['xlimv']    = [0.9, 300]\n",
    "spec_dict['ylimv']    = [0.5, None]\n",
    "spec_dict['xlimc']    = [-1,1]\n",
    "spec_dict['ylimc']    = [0,50]\n",
    "spec_dict['ytick']    = 5\n",
    "spec_dict['xtick']    = 0.2\n",
    "spec_dict['bin']      = 0.1\n",
    "spec_dict['rotation'] = 45\n",
    "\n",
    "acc_train = {}\n",
    "acc_val = {}\n",
    "# Precompute accuracy values for each model (only once)\n",
    "for model in models:\n",
    "    acct = []  # Reset accuracy list for each model\n",
    "    accv = []\n",
    "    for i in range(1, outerFolds+1):  # Loop over first parameter\n",
    "        for j in range(1, innerFolds+1):  # Loop over second parameter\n",
    "            file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "            filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "\n",
    "            # Load accuracy data from pickle file (avoid reloading for each iteration)\n",
    "            with open(resultsPath + filename + '.pickle', 'rb') as f:\n",
    "                shn = pickle.load(f)\n",
    "\n",
    "            # Append the accuracy to the list\n",
    "            acct.append(shn['training_loss_curve'])\n",
    "            accv.append(shn['validation_loss_curve'])\n",
    "\n",
    "    # Append the accuracy to the list\n",
    "    acc_train[model] = acct\n",
    "    acc_val[model] = accv\n",
    "\n",
    "fig = eegvislib.overfitting_inspection(models, acc_train, acc_val, spec_dict)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f85c88-3438-442e-89ee-b1fdb40229ee",
   "metadata": {},
   "source": [
    "## Analysis Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474405ed-65b1-4a44-9166-0dc03cdc7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'shn7db'\n",
    "f_lim = [1,45]\n",
    "spec_dict = {'font':12,\n",
    "             'linew':1,\n",
    "             'cmap':'RdBu_r',\n",
    "             'bands': {'$\\\\delta$':  [0,4],\n",
    "                       '$\\\\theta$':  [4,8],\n",
    "                       '$\\\\alpha$':  [8,12],\n",
    "                       '$\\\\beta_1$': [12,16],\n",
    "                       '$\\\\beta_2$': [16,20],\n",
    "                       '$\\\\beta_3$': [20,28],\n",
    "                       '$\\\\gamma$': [28,f_lim[1]]},\n",
    "             'classlabels': classlabels,\n",
    "             'figdim': [4,1],\n",
    "             'plot_type': 'second',\n",
    "             'cmap': 'RdBu_r',\n",
    "             'figname': 'uniqueConfigDense'}\n",
    "\n",
    "spec_dict['xticks'] = [i for i in spec_dict['bands'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa8bad-23d5-402e-be22-4ab42bd902f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_weights = []\n",
    "for i in range(1,outerFolds+1):\n",
    "    for j in range(1,innerFolds+1):\n",
    "        file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "        filename = f'alz_flt_125_{model}_{file_suffix}_000050_019_004'\n",
    "        shn = torch.load(modelsPath + filename + '.pt')\n",
    "        fig, mask = eegvislib.denseweights_plot(shn,'Dense',spec_dict)\n",
    "        matrix_weights.append(mask)\n",
    "        plt.close()\n",
    "        \n",
    "matrix_count = {}\n",
    "# Count occurrences of each matrix\n",
    "for matrix in matrix_weights:\n",
    "    matrix_tuple = tuple(map(tuple, matrix))  # Convert to a hashable format\n",
    "    if matrix_tuple in matrix_count:\n",
    "        matrix_count[matrix_tuple] += 1\n",
    "    else:\n",
    "        matrix_count[matrix_tuple] = 1\n",
    "\n",
    "# Convert counts back to a list of matrices\n",
    "unique_matrices = [np.array(matrix) for matrix in matrix_count.keys()]\n",
    "counts = list(matrix_count.values())\n",
    "\n",
    "cmap = ListedColormap(['white', 'red', 'blue', 'green'])\n",
    "\n",
    "# Now you have a list of unique matrices\n",
    "fig, ax = plt.subplots(len(unique_matrices),1,\n",
    "                       figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]*len(unique_matrices)),\n",
    "                       constrained_layout=True)\n",
    "for i in range(len(unique_matrices)):\n",
    "    ax[i].set_title(f'Number of Splits with this config.: {counts[i]}', fontsize=spec_dict['font'])\n",
    "    ax[i].imshow(unique_matrices[i], aspect='auto', \n",
    "                 cmap=cmap, interpolation='nearest')\n",
    "    ax[i].set_yticks(np.arange(0, 3))\n",
    "    ax[i].set_yticklabels(labels=spec_dict['classlabels'], fontsize=spec_dict['font']-4)\n",
    "    ax[i].set_xticks(np.arange(0, len(spec_dict['xticks']), 1))\n",
    "    ax[i].set_xticklabels(spec_dict['xticks'], fontsize=spec_dict['font']-4)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d44c0-2a08-4e2d-853c-b911d3b71e78",
   "metadata": {},
   "source": [
    "## Analysis Statical Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d7dd7-29f2-4d14-a97a-609230ec7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load accuracy data for each model\n",
    "def load_accuracy_data(model, path, folds, task='alz', pipe='flt', srate='125', lr='000050', ch='019', w='004', metric='accuracy_weighted'):\n",
    "    acc = []\n",
    "    for i in range(folds[0][0], folds[0][1]+1):  # Loop over first parameter\n",
    "        for j in range(folds[1][0], folds[1][1]+1):  # Loop over second parameter\n",
    "            file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "            filename = f'{task}_{pipe}_{srate}_{model}_{file_suffix}_{lr}_{ch}_{w}'\n",
    "            with open(path + filename + '.pickle', 'rb') as f:\n",
    "                shn = pickle.load(f)\n",
    "            if isinstance(shn, dict):\n",
    "                acc.append(shn['accuracy_weighted'])\n",
    "            else:\n",
    "                acc.append(shn)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de358e-a8c3-4cdb-8b8f-49114fcff333",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "folds = [[1,outerFolds],[1,innerFolds]]\n",
    "task='alz'\n",
    "pipe='flt'\n",
    "srate='125'\n",
    "model = 'shn7db'\n",
    "lr='000050'\n",
    "ch='019'\n",
    "w='004'\n",
    "accMLRM = []\n",
    "accshnMLRM = []\n",
    "path = numericPath + 'StatisticalModels' + sep + 'Results' + sep\n",
    "for i in range(folds[0][0], folds[0][1]+1):  # Loop over first parameter\n",
    "    for j in range(folds[1][0], folds[1][1]+1):  # Loop over second parameter\n",
    "        file_suffix = f'00{i}_00{j}' if i != 10 else f'0{i}_00{j}'\n",
    "        filename = f'{task}_{pipe}_{srate}_{model}_{file_suffix}_{lr}_{ch}_{w}'\n",
    "        with open(path + filename + '.pickle', 'rb') as f:\n",
    "            shn = pickle.load(f)\n",
    "        accMLRM.append(shn['MLRM_accuracy_weighted'])\n",
    "        accshnMLRM.append(shn['shnMLRM_accuracy_weighted'])\n",
    "\n",
    "metrics['MLRM'] = accMLRM\n",
    "metrics['shnMLRM'] = accshnMLRM\n",
    "\n",
    "model = 'shn7db'\n",
    "path = resultsPath\n",
    "metrics['shn7db'] = load_accuracy_data(model, resultsPath, [[1,outerFolds],[1,innerFolds]])\n",
    "\n",
    "model = 'shn0'\n",
    "path = resultsPath\n",
    "metrics['shn0'] = load_accuracy_data(model, resultsPath, [[1,outerFolds],[1,innerFolds]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae802a4-b145-4473-871f-83e277a856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = {'figdim': [7,5],\n",
    "             'jitter': 0.02,\n",
    "             's': 5,\n",
    "             'font': 16,\n",
    "             'rotation': 45,\n",
    "             'xticks': ['MLRM', 'shnMLRM', 'Med-ShallowNet', 'ShallowNet'],\n",
    "             'ylim': [20,105],\n",
    "             'linew':2,\n",
    "             'accrandom': 1/len(classlabels),\n",
    "             'marker': 'o',\n",
    "             'linestyle': '--',\n",
    "             'color': 'tab:blue',\n",
    "             'loc': 'upper center',\n",
    "             'figname': 'statModelComparison'}\n",
    "\n",
    "def stat_comparison(metrics, spec_dict):\n",
    "    df = pd.DataFrame(metrics)*100\n",
    "    # Plot setup\n",
    "    fig, ax = plt.subplots(figsize=(spec_dict['figdim'][0], spec_dict['figdim'][1]))\n",
    "    \n",
    "    box = ax.boxplot(df, showfliers=False, widths=0.6, medianprops=dict(color=\"none\"))\n",
    "    # Add jittered scatter points\n",
    "    for i, col in enumerate(df.columns, start=1):\n",
    "        jittered_x = np.random.normal(i, spec_dict['jitter'], size=len(df[col]))\n",
    "        ax.scatter(jittered_x, df[col], color='black', alpha=1, s=spec_dict['s'])\n",
    "    \n",
    "    # Set labels and ticks\n",
    "    ax.set_ylabel('Median Weighted Accuracy %', fontsize=spec_dict['font']-2, color='tab:blue')\n",
    "    ax.set_xticks(range(1, len(df.columns) + 1))\n",
    "    ax.set_xticklabels(spec_dict['xticks'], rotation=spec_dict['rotation'], fontsize=spec_dict['font']-4)\n",
    "    ax.set_ylim(spec_dict['ylim'][0], spec_dict['ylim'][1])\n",
    "    ax.axhline(spec_dict['accrandom']*100, linestyle='--', linewidth=spec_dict['linew'], color='red')\n",
    "    ax.set_title(\"Comparison with Multinomial Logistic Regression\", fontsize=spec_dict['font'])\n",
    "    \n",
    "    # Display median values and connect them with a line\n",
    "    medians = [np.median(df[col]) for col in df.columns]\n",
    "    for i, median in enumerate(medians, start=1):\n",
    "        ax.text(i, spec_dict['ylim'][0]+2, f'{median:.1f}%', ha='center', va='bottom',\n",
    "                color=spec_dict['color'], fontsize=spec_dict['font']-6, fontweight='bold')\n",
    "    ax.plot(range(1, len(medians) + 1), medians, marker=spec_dict['marker'], \n",
    "            linestyle=spec_dict['linestyle'], color=spec_dict['color'], linewidth=spec_dict['linew'])\n",
    "    \n",
    "    # Custom legend\n",
    "    legend_elements = [Line2D([0], [0], marker='.', color='k', label='Single Split', linestyle='None'),\n",
    "                       Line2D([0], [0], label=f'{spec_dict['accrandom']:.0%} Random Guess', linestyle=spec_dict['linestyle'],\n",
    "                              linewidth=spec_dict['linew'], color='red')\n",
    "                      ]\n",
    "    \n",
    "    ax.legend(handles=legend_elements, loc=spec_dict['loc'], fontsize=spec_dict['font']-6)\n",
    "    return fig\n",
    "\n",
    "fig = stat_comparison(metrics, spec_dict)\n",
    "# Save and display\n",
    "if save_img:\n",
    "    fig.savefig(imgPath + spec_dict['figname'] + imgs_format,\n",
    "                transparent=False, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff96568-6418-4f32-b09b-eaf2ff6dc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ np.mean(i) for i in metrics.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ae897-c3d1-4479-9a51-b6322ed30f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
